{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_to_encode = True # if you need to clean and encode texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384764\n"
     ]
    }
   ],
   "source": [
    "import encoder\n",
    "\n",
    "if (need_to_encode):\n",
    "    model = encoder.parse_model('models/ruwikiruscorpora_upos_skipgram_300_2_2018.vec')\n",
    "    \n",
    "    print(len(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean train texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4492 texsts are loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yordwynn/repos/urban-waffle/encoder.py:59: FutureWarning: Possible nested set at position 30\n",
      "  text = re.sub('[.,:;_%©?*,!@#$%^&()\\d]|[+=]|[[]|[]]|[/]|\"|\\s{2,}|-', ' ', text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 texts are cleaned\n",
      "досье_NOUN роман_NOUN досье_NOUN егоров_NOUN перевод_NOUN палимпсест_NOUN издательство_NOUN оформление_NOUN начаться_VERB июльский_ADJ поехать_VERB отпуск_NOUN тогдашний_ADJ подруга_NOUN брюнетка_NOUN грозный_NOUN характер_NOUN отец_NOUN согласиться_VERB дать_VERB машина_NOUN новенький_ADJ рено_NOUN удовольствие_NOUN пролетать_VERB километр_NOUN национальный_ADJ автострада_NOUN департамент_NOUN запад_NOUN франция_NOUN побережье_NOUN атлантический_ADJ океан_NOUN далее_ADV прима_NOUN веда_NOUN серия_NOUN ехать_VERB слегка_ADV превышать_VERB скорость_NOUN рисковать_VERB прямая_NOUN линия_NOUN зелёный_ADJ свет_NOUN светофор_NOUN гарантировать_VERB полный_ADJ безопасность_NOUN момент_NOUN приближаться_VERB светофор_NOUN наперерез_ADV выскочить_VERB фольксваген_NOUN резко_ADV вывернуть_VERB руль_NOUN избежать_VERB столкновение_NOUN получиться_VERB потерять_VERB управление_NOUN рено_NOUN вылететь_VERB шоссе_NOUN пробить_VERB ограждение_NOUN скатиться_VERB крутой_ADJ откос_NOUN замереть_VERB знать_VERB несколько_ADV метр_NOUN могучий_ADJ стекло_NOUN разлететься_VERB мелкий_ADJ осколок_NOUN поранить_VERB лицо_NOUN софи_NOUN выбраться_VERB груда_NOUN бесформенный_ADJ железо_NOUN дорога_NOUN собраться_VERB зевака_NOUN успеть_VERB вызвать_VERB полиция_NOUN пожарный_ADJ посередине_ADV перекрёсток_NOUN неподвижно_ADV стоялый_ADJ фольксваген_NOUN разбитый_ADJ передний_ADJ левый_ADJ крыло_NOUN машина_NOUN вытекать_VERB густой_ADJ жидкость_NOUN выпускать_VERB рука_NOUN руль_NOUN водитель_NOUN спрашивать_VERB произойти_VERB допросить_VERB поздний_ADJ полицейский_NOUN дать_VERB несвязный_ADJ показание_NOUN светофор_NOUN внимание_NOUN обратить_VERB хорошо_ADV знать_VERB дорога_NOUN ездить_VERB каждый_ADJ день_NOUN откуда_ADV ехать_VERB серный_ADJ источник_NOUN французский_ADJ департамент_NOUN верхний_ADJ пиренеи_NOUN горнолыжный_ADJ курорт_NOUN играть_VERB карта_NOUN извинить_VERB пить_VERB выпить_VERB друг_NOUN обычно_ADV идти_VERB восемьдесят_NUM девять_NUM мочь_NOUN поделать_VERB человек_NOUN дать_VERB выбирать_VERB возраст_NOUN жена_NOUN жена_NOUN сломать_VERB рука_NOUN сказать_VERB пожарный_ADJ ерунда_NOUN ремонт_NOUN машина_NOUN прийтись_VERB дорого_ADV заплатить_VERB палач_NOUN восемьдесят_NUM девять_NUM восемьдесят_NUM девять_NUM выпить_VERB приятель_NOUN повезти_VERB жена_NOUN домой_ADV красный_ADJ фольксваген_NOUN сигнал_NOUN светофор_NOUN ничуть_ADV беспокоить_VERB едва_ADV отправить_VERB праотец_NOUN молодая_NOUN человек_NOUN впереди_ADV целое_NOUN будущее_NOUN заботить_VERB намного_ADV маленький_ADJ стоимость_NOUN ремонт_NOUN собственный_ADJ тачка_NOUN дунуть_VERB трубка_NOUN старый_ADJ смочь_VERB болеть_VERB ребро_NOUN сделать_VERB заявление_NOUN забрать_VERB багаж_NOUN дождаться_VERB\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "if (need_to_encode):\n",
    "    texts = encoder.load_from_pickle('data/train_texts_cleaned_short.pickle')\n",
    "    print(f'{len(texts)} texsts are loaded')\n",
    "\n",
    "    cleaned_texts = list(map(lambda t: encoder.clean_text(t, model), texts[:100]))\n",
    "    print(f'{len(cleaned_texts)} texts are cleaned')\n",
    "    print(cleaned_texts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode texts to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 texts are encoded\n",
      "[[ 0.056797  0.077029  0.041735 ... -0.065106 -0.021656 -0.030767]\n",
      " [ 0.031343  0.034474  0.053584 ... -0.02193   0.020418 -0.079924]\n",
      " [ 0.056797  0.077029  0.041735 ... -0.065106 -0.021656 -0.030767]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]]\n"
     ]
    }
   ],
   "source": [
    "if (need_to_encode):\n",
    "    encoded = list(map(lambda t: encoder.encode_text(t, model, (256, 300)), cleaned_texts))\n",
    "\n",
    "    print(f'{len(encoded)} texts are encoded')\n",
    "    print(encoded[1])\n",
    "\n",
    "    encoder.save_to_pickle(encoded, 'data/train_texts_cleaned_short_encoded.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4492 labels are loaded\n",
      "100 encoded texts are loaded\n",
      "[[ 0.056797  0.077029  0.041735 ... -0.065106 -0.021656 -0.030767]\n",
      " [ 0.031343  0.034474  0.053584 ... -0.02193   0.020418 -0.079924]\n",
      " [ 0.056797  0.077029  0.041735 ... -0.065106 -0.021656 -0.030767]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]]\n"
     ]
    }
   ],
   "source": [
    "labels = encoder.load_from_pickle('data/train_labels2.pickle')\n",
    "encoded = encoder.load_from_pickle('data/train_texts_cleaned_short_encoded.pickle')\n",
    "\n",
    "print(f'{len(labels)} labels are loaded')\n",
    "print(f'{len(encoded)} encoded texts are loaded')\n",
    "print(encoded[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert load data to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 encoded texts are converted to tensors\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "tensors_x = torch.FloatTensor(encoded).view(100, 1, 256, 300)\n",
    "tensors_y = torch.FloatTensor(labels[:100])\n",
    "\n",
    "dataset = TensorDataset(tensors_x, tensors_y)\n",
    "\n",
    "print(f'{len(dataset)} encoded texts are converted to tensors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data to train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "#I took train and val sets in a ratio of 7 to 3\n",
    "train, val = random_split(dataset, [70, 30])\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=4)\n",
    "val_loader = DataLoader(val, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from models.convnet import ConvNet\n",
    "from model_utils import train\n",
    "import torch.optim\n",
    "\n",
    "#[conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "im_size = (256, 300, 1)\n",
    "conv_params = [(256, 5, 2), (256, 5, 2)]\n",
    "linear_params = [32, 2]\n",
    "learning_rate = 1e-2\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using device:', device)\n",
    "    \n",
    "model = ConvNet(im_size, conv_params, linear_params)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Точность должна быть больше 70%\n",
    "#train(model, train_loader, val_loader, optimizer, device, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from model_utils import eval_model\n",
    "\n",
    "pred, groundtruth = eval_model(val_loader, model, device)\n",
    "print(pred)\n",
    "print(groundtruth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.567\n",
      "f1 score: 0.723\n",
      "recall: 1.000\n",
      "precision: 0.567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "print(f'accuracy: {accuracy_score(pred, groundtruth):.3f}')\n",
    "print(f'f1 score: {f1_score(pred, groundtruth):.3f}')\n",
    "print(f'recall: {recall_score(pred, groundtruth):.3f}')\n",
    "print(f'precision: {precision_score(pred, groundtruth):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
