{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_to_encode = True # if you need to clean and encode texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384764\n"
     ]
    }
   ],
   "source": [
    "import encoder\n",
    "\n",
    "if (need_to_encode):\n",
    "    model = encoder.parse_model('models/ruwikiruscorpora_upos_skipgram_300_2_2018.vec')\n",
    "    \n",
    "    print(len(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean train texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4492 texsts are loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yordwynn/repos/urban-waffle/encoder.py:59: FutureWarning: Possible nested set at position 30\n",
      "  text = re.sub('[.,:;_%©?*,!@#$%^&()\\d]|[+=]|[[]|[]]|[/]|\"|\\s{2,}|-', ' ', text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 texts are cleaned\n",
      "досье_NOUN роман_NOUN досье_NOUN егоров_NOUN перевод_NOUN палимпсест_NOUN издательство_NOUN оформление_NOUN начаться_VERB июльский_ADJ поехать_VERB отпуск_NOUN тогдашний_ADJ подруга_NOUN брюнетка_NOUN грозный_NOUN характер_NOUN отец_NOUN согласиться_VERB дать_VERB машина_NOUN новенький_ADJ рено_NOUN удовольствие_NOUN пролетать_VERB километр_NOUN национальный_ADJ автострада_NOUN департамент_NOUN запад_NOUN франция_NOUN побережье_NOUN атлантический_ADJ океан_NOUN далее_ADV прима_NOUN веда_NOUN серия_NOUN ехать_VERB слегка_ADV превышать_VERB скорость_NOUN рисковать_VERB прямая_NOUN линия_NOUN зелёный_ADJ свет_NOUN светофор_NOUN гарантировать_VERB полный_ADJ безопасность_NOUN момент_NOUN приближаться_VERB светофор_NOUN наперерез_ADV выскочить_VERB фольксваген_NOUN резко_ADV вывернуть_VERB руль_NOUN избежать_VERB столкновение_NOUN получиться_VERB потерять_VERB управление_NOUN рено_NOUN вылететь_VERB шоссе_NOUN пробить_VERB ограждение_NOUN скатиться_VERB крутой_ADJ откос_NOUN замереть_VERB знать_VERB несколько_ADV метр_NOUN могучий_ADJ стекло_NOUN разлететься_VERB мелкий_ADJ осколок_NOUN поранить_VERB лицо_NOUN софи_NOUN выбраться_VERB груда_NOUN бесформенный_ADJ железо_NOUN дорога_NOUN собраться_VERB зевака_NOUN успеть_VERB вызвать_VERB полиция_NOUN пожарный_ADJ посередине_ADV перекрёсток_NOUN неподвижно_ADV стоялый_ADJ фольксваген_NOUN разбитый_ADJ передний_ADJ левый_ADJ крыло_NOUN машина_NOUN вытекать_VERB густой_ADJ жидкость_NOUN выпускать_VERB рука_NOUN руль_NOUN водитель_NOUN спрашивать_VERB произойти_VERB допросить_VERB поздний_ADJ полицейский_NOUN дать_VERB несвязный_ADJ показание_NOUN светофор_NOUN внимание_NOUN обратить_VERB хорошо_ADV знать_VERB дорога_NOUN ездить_VERB каждый_ADJ день_NOUN откуда_ADV ехать_VERB серный_ADJ источник_NOUN французский_ADJ департамент_NOUN верхний_ADJ пиренеи_NOUN горнолыжный_ADJ курорт_NOUN играть_VERB карта_NOUN извинить_VERB пить_VERB выпить_VERB друг_NOUN обычно_ADV идти_VERB восемьдесят_NUM девять_NUM мочь_NOUN поделать_VERB человек_NOUN дать_VERB выбирать_VERB возраст_NOUN жена_NOUN жена_NOUN сломать_VERB рука_NOUN сказать_VERB пожарный_ADJ ерунда_NOUN ремонт_NOUN машина_NOUN прийтись_VERB дорого_ADV заплатить_VERB палач_NOUN восемьдесят_NUM девять_NUM восемьдесят_NUM девять_NUM выпить_VERB приятель_NOUN повезти_VERB жена_NOUN домой_ADV красный_ADJ фольксваген_NOUN сигнал_NOUN светофор_NOUN ничуть_ADV беспокоить_VERB едва_ADV отправить_VERB праотец_NOUN молодая_NOUN человек_NOUN впереди_ADV целое_NOUN будущее_NOUN заботить_VERB намного_ADV маленький_ADJ стоимость_NOUN ремонт_NOUN собственный_ADJ тачка_NOUN дунуть_VERB трубка_NOUN старый_ADJ смочь_VERB болеть_VERB ребро_NOUN сделать_VERB заявление_NOUN забрать_VERB багаж_NOUN дождаться_VERB\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "if (need_to_encode):\n",
    "    texts = encoder.load_from_pickle('data/train_texts_cleaned_short.pickle')\n",
    "    print(f'{len(texts)} texsts are loaded')\n",
    "\n",
    "    cleaned_texts = list(map(lambda t: encoder.clean_text(t, model), texts[:100]))\n",
    "    print(f'{len(cleaned_texts)} texts are cleaned')\n",
    "    print(cleaned_texts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode texts to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 texts are encoded\n",
      "[[ 0.056797  0.077029  0.041735 ... -0.065106 -0.021656 -0.030767]\n",
      " [ 0.031343  0.034474  0.053584 ... -0.02193   0.020418 -0.079924]\n",
      " [ 0.056797  0.077029  0.041735 ... -0.065106 -0.021656 -0.030767]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]]\n"
     ]
    }
   ],
   "source": [
    "if (need_to_encode):\n",
    "    encoded = list(map(lambda t: encoder.encode_text(t, model, (256, 300)), cleaned_texts))\n",
    "\n",
    "    print(f'{len(encoded)} texts are encoded')\n",
    "    print(encoded[1])\n",
    "\n",
    "    encoder.save_to_pickle(encoded, 'data/train_texts_cleaned_short_encoded.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4492 labels are loaded\n",
      "100 encoded texts are loaded\n",
      "[[ 0.056797  0.077029  0.041735 ... -0.065106 -0.021656 -0.030767]\n",
      " [ 0.031343  0.034474  0.053584 ... -0.02193   0.020418 -0.079924]\n",
      " [ 0.056797  0.077029  0.041735 ... -0.065106 -0.021656 -0.030767]\n",
      " ...\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
      " [ 0.        0.        0.       ...  0.        0.        0.      ]]\n"
     ]
    }
   ],
   "source": [
    "labels = encoder.load_from_pickle('data/train_labels2.pickle')\n",
    "encoded = encoder.load_from_pickle('data/train_texts_cleaned_short_encoded.pickle')\n",
    "\n",
    "print(f'{len(labels)} labels are loaded')\n",
    "print(f'{len(encoded)} encoded texts are loaded')\n",
    "print(encoded[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert load data to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "100 encoded texts are converted to tensors\n",
      "(tensor([[ 0.0568,  0.0770,  0.0417,  ..., -0.0651, -0.0217, -0.0308],\n",
      "        [ 0.0313,  0.0345,  0.0536,  ..., -0.0219,  0.0204, -0.0799],\n",
      "        [ 0.0568,  0.0770,  0.0417,  ..., -0.0651, -0.0217, -0.0308],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]), tensor(1.))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "tensors_x = torch.FloatTensor(encoded)\n",
    "tensors_y = torch.FloatTensor(labels[:100])\n",
    "\n",
    "dataset = TensorDataset(tensors_x, tensors_y)\n",
    "\n",
    "print(f'{len(dataset)} encoded texts are converted to tensors')\n",
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data to train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: 1\n",
      "val set: 1\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "#I took train and val sets in a ratio of 7 to 3\n",
    "train, val = random_split(dataset, [70, 30])\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=100)\n",
    "val_loader = DataLoader(val, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
